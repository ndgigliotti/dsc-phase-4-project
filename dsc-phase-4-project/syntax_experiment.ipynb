{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)"
  },
  "interpreter": {
   "hash": "45e948d0256f8c78ae85303b642a175be3add64c95f2eaa9e19fcfd099775c4c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            0              1         2        3        4             5     \\\n",
       "0      anarchism    reciprocity      with  despite  present        murray   \n",
       "1     originated    qualitative       the      his     best      rothbard   \n",
       "2             as    impairments     aegis   injury    sound       written   \n",
       "3              a             in        of    booth  editing            in   \n",
       "4           term  communication      zeus  managed      one           one   \n",
       "...          ...            ...       ...      ...      ...           ...   \n",
       "9995        lack            the     stage      one      the            is   \n",
       "9996          of        goddess     below     nine      ayn             a   \n",
       "9997      social         athena  breaking    three     rand         crude   \n",
       "9998          or       provides       his     zero     cult  reductionist   \n",
       "9999   emotional            him       leg       to       by           who   \n",
       "\n",
       "          6          7           8            9     ...          1691  \\\n",
       "0     believes       that     century  mountainous  ...        mickey   \n",
       "1          man    focused        when      country  ...           was   \n",
       "2           is         on  physicists          due  ...       created   \n",
       "3      nothing  analyzing        were           to  ...            by   \n",
       "4          but        how        able          its  ...            ub   \n",
       "...        ...        ...         ...          ...  ...           ...   \n",
       "9995        of         in     austria          and  ...          made   \n",
       "9996         a        the     austria        being  ...     extensive   \n",
       "9997   science        two          is          the  ...  preparations   \n",
       "9998        of       zero           a        first  ...           for   \n",
       "9999   society         th     largely           to  ...             a   \n",
       "\n",
       "         1692       1693          1694        1695          1696        1697  \\\n",
       "0      public  botanical  increasingly           a           the          if   \n",
       "1     darshan     garden          more   premature        format      either   \n",
       "2     program        vol     difficult   explosion      although       party   \n",
       "3          to        six            to     another         there   disagreed   \n",
       "4          be       five         clean      common           are  neutrality   \n",
       "...       ...        ...           ...         ...           ...         ...   \n",
       "9995  memoirs         to            is         non    provisions       ozzie   \n",
       "9996       of         be         worth  commercial          that       smith   \n",
       "9997      the    malware           the    software      included         new   \n",
       "9998      new        has          risk          to  consultation        york   \n",
       "9999     york     become            of     support   arbitration        city   \n",
       "\n",
       "         1698    1699     1700  \n",
       "0         and    four     find  \n",
       "1     chicago    five     list  \n",
       "2         are    four       of  \n",
       "3       first   eight     once  \n",
       "4         and    four  popular  \n",
       "...       ...     ...      ...  \n",
       "9995      six      of     None  \n",
       "9996     four  poland     None  \n",
       "9997     zero    here     None  \n",
       "9998     four     you     None  \n",
       "9999     four     can     None  \n",
       "\n",
       "[10000 rows x 1701 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1691</th>\n      <th>1692</th>\n      <th>1693</th>\n      <th>1694</th>\n      <th>1695</th>\n      <th>1696</th>\n      <th>1697</th>\n      <th>1698</th>\n      <th>1699</th>\n      <th>1700</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>anarchism</td>\n      <td>reciprocity</td>\n      <td>with</td>\n      <td>despite</td>\n      <td>present</td>\n      <td>murray</td>\n      <td>believes</td>\n      <td>that</td>\n      <td>century</td>\n      <td>mountainous</td>\n      <td>...</td>\n      <td>mickey</td>\n      <td>public</td>\n      <td>botanical</td>\n      <td>increasingly</td>\n      <td>a</td>\n      <td>the</td>\n      <td>if</td>\n      <td>and</td>\n      <td>four</td>\n      <td>find</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>originated</td>\n      <td>qualitative</td>\n      <td>the</td>\n      <td>his</td>\n      <td>best</td>\n      <td>rothbard</td>\n      <td>man</td>\n      <td>focused</td>\n      <td>when</td>\n      <td>country</td>\n      <td>...</td>\n      <td>was</td>\n      <td>darshan</td>\n      <td>garden</td>\n      <td>more</td>\n      <td>premature</td>\n      <td>format</td>\n      <td>either</td>\n      <td>chicago</td>\n      <td>five</td>\n      <td>list</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>as</td>\n      <td>impairments</td>\n      <td>aegis</td>\n      <td>injury</td>\n      <td>sound</td>\n      <td>written</td>\n      <td>is</td>\n      <td>on</td>\n      <td>physicists</td>\n      <td>due</td>\n      <td>...</td>\n      <td>created</td>\n      <td>program</td>\n      <td>vol</td>\n      <td>difficult</td>\n      <td>explosion</td>\n      <td>although</td>\n      <td>party</td>\n      <td>are</td>\n      <td>four</td>\n      <td>of</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a</td>\n      <td>in</td>\n      <td>of</td>\n      <td>booth</td>\n      <td>editing</td>\n      <td>in</td>\n      <td>nothing</td>\n      <td>analyzing</td>\n      <td>were</td>\n      <td>to</td>\n      <td>...</td>\n      <td>by</td>\n      <td>to</td>\n      <td>six</td>\n      <td>to</td>\n      <td>another</td>\n      <td>there</td>\n      <td>disagreed</td>\n      <td>first</td>\n      <td>eight</td>\n      <td>once</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>term</td>\n      <td>communication</td>\n      <td>zeus</td>\n      <td>managed</td>\n      <td>one</td>\n      <td>one</td>\n      <td>but</td>\n      <td>how</td>\n      <td>able</td>\n      <td>its</td>\n      <td>...</td>\n      <td>ub</td>\n      <td>be</td>\n      <td>five</td>\n      <td>clean</td>\n      <td>common</td>\n      <td>are</td>\n      <td>neutrality</td>\n      <td>and</td>\n      <td>four</td>\n      <td>popular</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>lack</td>\n      <td>the</td>\n      <td>stage</td>\n      <td>one</td>\n      <td>the</td>\n      <td>is</td>\n      <td>of</td>\n      <td>in</td>\n      <td>austria</td>\n      <td>and</td>\n      <td>...</td>\n      <td>made</td>\n      <td>memoirs</td>\n      <td>to</td>\n      <td>is</td>\n      <td>non</td>\n      <td>provisions</td>\n      <td>ozzie</td>\n      <td>six</td>\n      <td>of</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>of</td>\n      <td>goddess</td>\n      <td>below</td>\n      <td>nine</td>\n      <td>ayn</td>\n      <td>a</td>\n      <td>a</td>\n      <td>the</td>\n      <td>austria</td>\n      <td>being</td>\n      <td>...</td>\n      <td>extensive</td>\n      <td>of</td>\n      <td>be</td>\n      <td>worth</td>\n      <td>commercial</td>\n      <td>that</td>\n      <td>smith</td>\n      <td>four</td>\n      <td>poland</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>social</td>\n      <td>athena</td>\n      <td>breaking</td>\n      <td>three</td>\n      <td>rand</td>\n      <td>crude</td>\n      <td>science</td>\n      <td>two</td>\n      <td>is</td>\n      <td>the</td>\n      <td>...</td>\n      <td>preparations</td>\n      <td>the</td>\n      <td>malware</td>\n      <td>the</td>\n      <td>software</td>\n      <td>included</td>\n      <td>new</td>\n      <td>zero</td>\n      <td>here</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>or</td>\n      <td>provides</td>\n      <td>his</td>\n      <td>zero</td>\n      <td>cult</td>\n      <td>reductionist</td>\n      <td>of</td>\n      <td>zero</td>\n      <td>a</td>\n      <td>first</td>\n      <td>...</td>\n      <td>for</td>\n      <td>new</td>\n      <td>has</td>\n      <td>risk</td>\n      <td>to</td>\n      <td>consultation</td>\n      <td>york</td>\n      <td>four</td>\n      <td>you</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>emotional</td>\n      <td>him</td>\n      <td>leg</td>\n      <td>to</td>\n      <td>by</td>\n      <td>who</td>\n      <td>society</td>\n      <td>th</td>\n      <td>largely</td>\n      <td>to</td>\n      <td>...</td>\n      <td>a</td>\n      <td>york</td>\n      <td>become</td>\n      <td>of</td>\n      <td>support</td>\n      <td>arbitration</td>\n      <td>city</td>\n      <td>four</td>\n      <td>can</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 1701 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "\n",
    "docs = pd.DataFrame(api.load(\"text8\")).T\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def word2vec(word):\n",
    "    vec = list(map(ord, list(word)))\n",
    "    return np.array(vec)\n",
    "\n",
    "\n",
    "def char_sum(word):\n",
    "    return np.sum(word2vec(word))\n",
    "\n",
    "def char_sum_vec(words):\n",
    "    return np.array(list(map(char_sum, words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'[1700] not found in axis'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-214774783e1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1700\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[1700] not found in axis'"
     ]
    }
   ],
   "source": [
    "docs = docs.drop(1700, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', ..., 'zzurf', 'zzz', 'zzzzzz'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "words = np.unique(docs.values.flatten())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ord() expected a character, but string of length 2 found",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-77525fcc5ef9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_vecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_vecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         ) from None\n\u001b[1;32m--> 379\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-023fb6377585>\u001b[0m in \u001b[0;36mword2vec\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ord() expected a character, but string of length 2 found"
     ]
    }
   ],
   "source": [
    "word_vecs = np.apply_along_axis(word2vec, 0, words)\n",
    "word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "a                       97\n",
       "aa                     194\n",
       "aaa                    291\n",
       "aaaa                   388\n",
       "aaaaaacceglllnorst    1874\n",
       "                      ... \n",
       "zzul                   469\n",
       "zzum                   470\n",
       "zzurf                  577\n",
       "zzz                    366\n",
       "zzzzzz                 732\n",
       "Length: 253833, dtype: int32"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "vocab = pd.Series(index=words, data=char_sum_vec(words))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "           n_trimmed  pct_trimmed\n0               4986     1.964284\ntotal_obs       4986     1.964284",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_trimmed</th>\n      <th>pct_trimmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4986</td>\n      <td>1.964284</td>\n    </tr>\n    <tr>\n      <th>total_obs</th>\n      <td>4986</td>\n      <td>1.964284</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "a                   97\n",
       "b                   98\n",
       "c                   99\n",
       "d                  100\n",
       "e                  101\n",
       "                  ... \n",
       "retslitteratur    1550\n",
       "waronterrorism    1550\n",
       "constructively    1550\n",
       "percussionists    1550\n",
       "postmodernists    1550\n",
       "Length: 248847, dtype: int32"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "from tools import outliers\n",
    "vocab = outliers.tukey_trim(vocab).sort_values()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                char_sum\n",
       "a                     97\n",
       "b                     98\n",
       "c                     99\n",
       "d                    100\n",
       "e                    101\n",
       "...                  ...\n",
       "retslitteratur      1550\n",
       "waronterrorism      1550\n",
       "constructively      1550\n",
       "percussionists      1550\n",
       "postmodernists      1550\n",
       "\n",
       "[248847 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>char_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>e</th>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>retslitteratur</th>\n      <td>1550</td>\n    </tr>\n    <tr>\n      <th>waronterrorism</th>\n      <td>1550</td>\n    </tr>\n    <tr>\n      <th>constructively</th>\n      <td>1550</td>\n    </tr>\n    <tr>\n      <th>percussionists</th>\n      <td>1550</td>\n    </tr>\n    <tr>\n      <th>postmodernists</th>\n      <td>1550</td>\n    </tr>\n  </tbody>\n</table>\n<p>248847 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "vocab = vocab.to_frame(\"char_sum\")\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   char_sum  len\n",
       "a        97    1\n",
       "b        98    1\n",
       "c        99    1\n",
       "d       100    1\n",
       "e       101    1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>char_sum</th>\n      <th>len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>97</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>98</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>99</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>d</th>\n      <td>100</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>e</th>\n      <td>101</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "vocab[\"len\"] = vocab.index.to_series().str.len()\n",
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "char_sum    0.997821\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "vocab[[\"char_sum\"]].corrwith(vocab[\"len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}